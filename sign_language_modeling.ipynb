{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-11T02:59:04.071864Z",
     "start_time": "2026-01-11T02:58:37.505619Z"
    }
   },
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Dropout, LSTM, Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import time"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\kongm\\PycharmProjects\\SignLanguage\\.venv3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T02:00:50.975221Z",
     "start_time": "2026-01-10T01:59:43.546208Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "# -------------------------\n",
    "# Settings\n",
    "# -------------------------\n",
    "DATASET_DIR = \"dataset\"\n",
    "SEQUENCE_LENGTH = 30\n",
    "N_FEATURES = 126\n",
    "SAVE_DIR = \"processed_data\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# -------------------------\n",
    "# Function to clean and fix sequence\n",
    "# -------------------------\n",
    "def clean_and_fix_sequence(df, target_len=SEQUENCE_LENGTH, n_features=N_FEATURES):\n",
    "    \"\"\"\n",
    "    Convert DataFrame to numeric, drop non-numeric rows, pad/truncate to target shape.\n",
    "    Returns: np.array of shape (target_len, n_features)\n",
    "    \"\"\"\n",
    "    # Convert to numeric, replace non-numeric with NaN\n",
    "    df_numeric = df.apply(pd.to_numeric, errors='coerce')\n",
    "    df_numeric = df_numeric.dropna(how='all')\n",
    "\n",
    "    # If empty, fill with zeros\n",
    "    if df_numeric.empty:\n",
    "        return np.zeros((target_len, n_features), dtype=np.float32)\n",
    "\n",
    "    # Convert to numpy\n",
    "    seq = df_numeric.values.astype(np.float32)\n",
    "\n",
    "    # Fix columns\n",
    "    n_rows, n_cols = seq.shape\n",
    "    if n_cols > n_features:\n",
    "        seq = seq[:, :n_features]\n",
    "    elif n_cols < n_features:\n",
    "        seq = np.hstack([seq, np.zeros((n_rows, n_features - n_cols), dtype=np.float32)])\n",
    "\n",
    "    # Fix rows (sequence length)\n",
    "    if n_rows > target_len:\n",
    "        seq = seq[:target_len, :]\n",
    "    elif n_rows < target_len:\n",
    "        seq = np.vstack([seq, np.zeros((target_len - n_rows, n_features), dtype=np.float32)])\n",
    "\n",
    "    return seq\n",
    "\n",
    "# -------------------------\n",
    "# Process entire dataset\n",
    "# -------------------------\n",
    "def process_dataset(dataset_dir=DATASET_DIR):\n",
    "    X, y = [], []\n",
    "    skipped_files = []\n",
    "\n",
    "    categories = [c for c in os.listdir(dataset_dir) if os.path.isdir(os.path.join(dataset_dir, c))]\n",
    "    print(f\"Found categories: {categories}\")\n",
    "\n",
    "    for category in categories:\n",
    "        kp_dir = os.path.join(dataset_dir, category, \"keypoints\")\n",
    "        if not os.path.isdir(kp_dir):\n",
    "            continue\n",
    "\n",
    "        files = os.listdir(kp_dir)\n",
    "        if not files:\n",
    "            print(f\"No CSV files found in {kp_dir}\")\n",
    "            continue\n",
    "\n",
    "        for csv_file in files:\n",
    "            csv_path = os.path.join(kp_dir, csv_file)\n",
    "            try:\n",
    "                df = pd.read_csv(csv_path, header=None)\n",
    "                keypoints = clean_and_fix_sequence(df)\n",
    "                X.append(keypoints)\n",
    "                y.append(category)\n",
    "            except Exception as e:\n",
    "                skipped_files.append(csv_path)\n",
    "                X.append(np.zeros((SEQUENCE_LENGTH, N_FEATURES), dtype=np.float32))\n",
    "                y.append(category)\n",
    "                print(f\"Warning: Could not read {csv_path}. Error: {e}\")\n",
    "\n",
    "    X = np.array(X, dtype=np.float32)\n",
    "    y = np.array(y)\n",
    "\n",
    "    # Encode labels\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "    y_onehot = to_categorical(y_encoded)\n",
    "\n",
    "    # Save processed data\n",
    "    np.save(os.path.join(SAVE_DIR, \"X_keypoints.npy\"), X)\n",
    "    np.save(os.path.join(SAVE_DIR, \"y_labels.npy\"), y_onehot)\n",
    "\n",
    "    # Save label mapping for later use\n",
    "    label_map = {i: label for i, label in enumerate(label_encoder.classes_)}\n",
    "    with open(os.path.join(SAVE_DIR, \"label_map.json\"), \"w\") as f:\n",
    "        json.dump(label_map, f, indent=2)\n",
    "\n",
    "    print(\"\\nDataset processed successfully!\")\n",
    "    print(f\"X shape: {X.shape}, y_onehot shape: {y_onehot.shape}\")\n",
    "    if skipped_files:\n",
    "        print(f\"Skipped {len(skipped_files)} files due to errors.\")\n",
    "        for f in skipped_files:\n",
    "            print(f\" - {f}\")\n",
    "\n",
    "    return X, y_onehot, label_encoder\n",
    "\n",
    "# -------------------------\n",
    "# Run preprocessing\n",
    "# -------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    X, y_onehot, label_encoder = process_dataset()\n"
   ],
   "id": "15428a4ade36f05d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found categories: ['again', 'Baby', 'Bad', 'bathroom', 'book', 'Brother', 'busy', 'Dad', 'do not want', 'Eat', 'Fast', 'father', 'Fine', 'finish', 'forget', 'Friend', 'Go', 'Good', 'Great', 'happy', 'He', 'hello', 'Help', 'how', 'I', 'is', 'learn', 'like', 'Love', 'marry', 'meet', 'milk', 'more', 'mother', 'My', 'name', 'need', 'nice', 'No', 'Nothing', 'please', 'question', 'right', 'sad', 'same', 'Say', 'See you later', 'see you letter', 'Sister', 'sleep', 'Stop', 'Teacher', 'thank you', 'want', 'We', 'what', 'What_s up', 'when', 'where', 'which', 'who', 'why', 'wrong', 'Yes', 'You', 'your']\n",
      "\n",
      "Dataset processed successfully!\n",
      "X shape: (3701, 30, 126), y_onehot shape: (3701, 65)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T02:15:21.735497Z",
     "start_time": "2026-01-10T02:14:20.520550Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Dropout, LSTM, Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# -------------------------\n",
    "# Settings\n",
    "# -------------------------\n",
    "DATA_DIR = \"processed_data\"\n",
    "MODEL_SAVE_PATH = \"sign_language_model.keras\"  # new Keras format\n",
    "SEQUENCE_LENGTH = 30\n",
    "N_FEATURES = 126\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 50\n",
    "PATIENCE = 10  # Early stopping patience\n",
    "\n",
    "# -------------------------\n",
    "# Load preprocessed data\n",
    "# -------------------------\n",
    "X = np.load(os.path.join(DATA_DIR, \"X_keypoints.npy\"))\n",
    "y = np.load(os.path.join(DATA_DIR, \"y_labels.npy\"))\n",
    "\n",
    "# Load label map\n",
    "with open(os.path.join(DATA_DIR, \"label_map.json\"), \"r\") as f:\n",
    "    label_map = json.load(f)\n",
    "\n",
    "NUM_CLASSES = y.shape[1]\n",
    "\n",
    "print(f\"X shape: {X.shape}, y shape: {y.shape}\")\n",
    "print(f\"Number of classes: {NUM_CLASSES}, Classes: {list(label_map.values())}\")\n",
    "\n",
    "# -------------------------\n",
    "# Train-test split\n",
    "# -------------------------\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}, Validation samples: {len(X_val)}\")\n",
    "\n",
    "# -------------------------\n",
    "# Model definition\n",
    "# -------------------------\n",
    "model = Sequential([\n",
    "    # 1D Conv layers for spatial info\n",
    "    Conv1D(64, kernel_size=3, activation='relu', input_shape=(SEQUENCE_LENGTH, N_FEATURES)),\n",
    "    Conv1D(128, kernel_size=3, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    # LSTM for temporal info\n",
    "    LSTM(64, return_sequences=False),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    # Output layer\n",
    "    Dense(NUM_CLASSES, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# -------------------------\n",
    "# Callbacks\n",
    "# -------------------------\n",
    "checkpoint = ModelCheckpoint(MODEL_SAVE_PATH, monitor='val_accuracy', save_best_only=True, verbose=1)\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=PATIENCE, restore_best_weights=True, verbose=1)\n",
    "\n",
    "# -------------------------\n",
    "# Train the model\n",
    "# -------------------------\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=[checkpoint, early_stop],\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Evaluate the model\n",
    "# -------------------------\n",
    "loss, accuracy = model.evaluate(X_val, y_val, verbose=0)\n",
    "print(f\"\\nâœ… Validation Loss: {loss:.4f}\")\n",
    "print(f\"âœ… Validation Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# -------------------------\n",
    "# Optional: Continue training with extra epochs\n",
    "# -------------------------\n",
    "EXTRA_EPOCHS = 15  # adjust as needed\n",
    "print(\"\\nðŸ”¹ Continuing training with extra epochs...\")\n",
    "\n",
    "# Load best saved model\n",
    "model = load_model(MODEL_SAVE_PATH)\n",
    "\n",
    "# Adjust patience for fine-tuning\n",
    "early_stop_extra = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1)\n",
    "\n",
    "history_extra = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=EXTRA_EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=[early_stop_extra, checkpoint],\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Final evaluation\n",
    "loss, accuracy = model.evaluate(X_val, y_val, verbose=0)\n",
    "print(f\"\\nâœ… Final Validation Loss: {loss:.4f}\")\n",
    "print(f\"âœ… Final Validation Accuracy: {accuracy:.4f}\")\n"
   ],
   "id": "ced235a3e075c5f1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (3701, 30, 126), y shape: (3701, 65)\n",
      "Number of classes: 65, Classes: ['Baby', 'Bad', 'Brother', 'Dad', 'Eat', 'Fine', 'Friend', 'Go', 'Good', 'Great', 'He', 'Help', 'I', 'Love', 'My', 'No', 'Nothing', 'Say', 'See you later', 'Sister', 'Stop', 'Teacher', 'We', 'What_s up', 'Yes', 'You', 'again', 'bathroom', 'book', 'busy', 'do not want', 'father', 'finish', 'forget', 'happy', 'hello', 'how', 'is', 'learn', 'like', 'marry', 'meet', 'milk', 'more', 'mother', 'name', 'need', 'nice', 'please', 'question', 'right', 'sad', 'same', 'see you letter', 'sleep', 'thank you', 'want', 'what', 'when', 'where', 'which', 'who', 'why', 'wrong', 'your']\n",
      "Training samples: 2960, Validation samples: 741\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_4 (Conv1D)           (None, 28, 64)            24256     \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 26, 128)           24704     \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPoolin  (None, 13, 128)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 13, 128)           0         \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 64)                49408     \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 65)                4225      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 102593 (400.75 KB)\n",
      "Trainable params: 102593 (400.75 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "178/185 [===========================>..] - ETA: 0s - loss: 3.8703 - accuracy: 0.0530\n",
      "Epoch 1: val_accuracy improved from -inf to 0.09582, saving model to sign_language_model.keras\n",
      "185/185 [==============================] - 3s 7ms/step - loss: 3.8518 - accuracy: 0.0537 - val_loss: 3.3028 - val_accuracy: 0.0958\n",
      "Epoch 2/50\n",
      "178/185 [===========================>..] - ETA: 0s - loss: 3.2189 - accuracy: 0.0934\n",
      "Epoch 2: val_accuracy improved from 0.09582 to 0.17544, saving model to sign_language_model.keras\n",
      "185/185 [==============================] - 1s 5ms/step - loss: 3.2092 - accuracy: 0.0936 - val_loss: 2.7438 - val_accuracy: 0.1754\n",
      "Epoch 3/50\n",
      "182/185 [============================>.] - ETA: 0s - loss: 2.6899 - accuracy: 0.2030\n",
      "Epoch 3: val_accuracy improved from 0.17544 to 0.33333, saving model to sign_language_model.keras\n",
      "185/185 [==============================] - 1s 5ms/step - loss: 2.6849 - accuracy: 0.2047 - val_loss: 2.2593 - val_accuracy: 0.3333\n",
      "Epoch 4/50\n",
      "184/185 [============================>.] - ETA: 0s - loss: 2.2862 - accuracy: 0.3037\n",
      "Epoch 4: val_accuracy improved from 0.33333 to 0.41970, saving model to sign_language_model.keras\n",
      "185/185 [==============================] - 1s 5ms/step - loss: 2.2845 - accuracy: 0.3041 - val_loss: 1.9689 - val_accuracy: 0.4197\n",
      "Epoch 5/50\n",
      "182/185 [============================>.] - ETA: 0s - loss: 2.0446 - accuracy: 0.3733\n",
      "Epoch 5: val_accuracy did not improve from 0.41970\n",
      "185/185 [==============================] - 1s 5ms/step - loss: 2.0423 - accuracy: 0.3726 - val_loss: 1.8960 - val_accuracy: 0.4157\n",
      "Epoch 6/50\n",
      "175/185 [===========================>..] - ETA: 0s - loss: 1.9079 - accuracy: 0.4089\n",
      "Epoch 6: val_accuracy improved from 0.41970 to 0.48313, saving model to sign_language_model.keras\n",
      "185/185 [==============================] - 1s 5ms/step - loss: 1.8929 - accuracy: 0.4149 - val_loss: 1.6316 - val_accuracy: 0.4831\n",
      "Epoch 7/50\n",
      "180/185 [============================>.] - ETA: 0s - loss: 1.6954 - accuracy: 0.4833\n",
      "Epoch 7: val_accuracy improved from 0.48313 to 0.61269, saving model to sign_language_model.keras\n",
      "185/185 [==============================] - 1s 5ms/step - loss: 1.6950 - accuracy: 0.4841 - val_loss: 1.3920 - val_accuracy: 0.6127\n",
      "Epoch 8/50\n",
      "177/185 [===========================>..] - ETA: 0s - loss: 1.5826 - accuracy: 0.5177\n",
      "Epoch 8: val_accuracy did not improve from 0.61269\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 1.5817 - accuracy: 0.5152 - val_loss: 1.3867 - val_accuracy: 0.5911\n",
      "Epoch 9/50\n",
      "185/185 [==============================] - ETA: 0s - loss: 1.5098 - accuracy: 0.5361\n",
      "Epoch 9: val_accuracy did not improve from 0.61269\n",
      "185/185 [==============================] - 1s 5ms/step - loss: 1.5098 - accuracy: 0.5361 - val_loss: 1.2576 - val_accuracy: 0.6086\n",
      "Epoch 10/50\n",
      "174/185 [===========================>..] - ETA: 0s - loss: 1.3747 - accuracy: 0.5711\n",
      "Epoch 10: val_accuracy improved from 0.61269 to 0.62618, saving model to sign_language_model.keras\n",
      "185/185 [==============================] - 1s 5ms/step - loss: 1.3794 - accuracy: 0.5686 - val_loss: 1.2338 - val_accuracy: 0.6262\n",
      "Epoch 11/50\n",
      "178/185 [===========================>..] - ETA: 0s - loss: 1.2945 - accuracy: 0.5948\n",
      "Epoch 11: val_accuracy did not improve from 0.62618\n",
      "185/185 [==============================] - 1s 5ms/step - loss: 1.2964 - accuracy: 0.5949 - val_loss: 1.3357 - val_accuracy: 0.5749\n",
      "Epoch 12/50\n",
      "177/185 [===========================>..] - ETA: 0s - loss: 1.2034 - accuracy: 0.6296\n",
      "Epoch 12: val_accuracy improved from 0.62618 to 0.72200, saving model to sign_language_model.keras\n",
      "185/185 [==============================] - 1s 5ms/step - loss: 1.2053 - accuracy: 0.6304 - val_loss: 1.0139 - val_accuracy: 0.7220\n",
      "Epoch 13/50\n",
      "174/185 [===========================>..] - ETA: 0s - loss: 1.1401 - accuracy: 0.6491\n",
      "Epoch 13: val_accuracy improved from 0.72200 to 0.73144, saving model to sign_language_model.keras\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 1.1403 - accuracy: 0.6493 - val_loss: 0.9519 - val_accuracy: 0.7314\n",
      "Epoch 14/50\n",
      "176/185 [===========================>..] - ETA: 0s - loss: 1.0537 - accuracy: 0.6907\n",
      "Epoch 14: val_accuracy improved from 0.73144 to 0.73279, saving model to sign_language_model.keras\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 1.0536 - accuracy: 0.6889 - val_loss: 0.9071 - val_accuracy: 0.7328\n",
      "Epoch 15/50\n",
      "183/185 [============================>.] - ETA: 0s - loss: 1.0239 - accuracy: 0.6796\n",
      "Epoch 15: val_accuracy did not improve from 0.73279\n",
      "185/185 [==============================] - 1s 5ms/step - loss: 1.0244 - accuracy: 0.6794 - val_loss: 1.0516 - val_accuracy: 0.6559\n",
      "Epoch 16/50\n",
      "174/185 [===========================>..] - ETA: 0s - loss: 0.9660 - accuracy: 0.6954\n",
      "Epoch 16: val_accuracy improved from 0.73279 to 0.75304, saving model to sign_language_model.keras\n",
      "185/185 [==============================] - 1s 5ms/step - loss: 0.9629 - accuracy: 0.6990 - val_loss: 0.8819 - val_accuracy: 0.7530\n",
      "Epoch 17/50\n",
      "183/185 [============================>.] - ETA: 0s - loss: 0.9275 - accuracy: 0.7124\n",
      "Epoch 17: val_accuracy improved from 0.75304 to 0.77058, saving model to sign_language_model.keras\n",
      "185/185 [==============================] - 1s 5ms/step - loss: 0.9260 - accuracy: 0.7128 - val_loss: 0.8040 - val_accuracy: 0.7706\n",
      "Epoch 18/50\n",
      "185/185 [==============================] - ETA: 0s - loss: 0.8734 - accuracy: 0.7382\n",
      "Epoch 18: val_accuracy improved from 0.77058 to 0.77733, saving model to sign_language_model.keras\n",
      "185/185 [==============================] - 1s 5ms/step - loss: 0.8734 - accuracy: 0.7382 - val_loss: 0.7729 - val_accuracy: 0.7773\n",
      "Epoch 19/50\n",
      "178/185 [===========================>..] - ETA: 0s - loss: 0.8013 - accuracy: 0.7567\n",
      "Epoch 19: val_accuracy did not improve from 0.77733\n",
      "185/185 [==============================] - 1s 5ms/step - loss: 0.7976 - accuracy: 0.7584 - val_loss: 0.7717 - val_accuracy: 0.7746\n",
      "Epoch 20/50\n",
      "179/185 [============================>.] - ETA: 0s - loss: 0.7759 - accuracy: 0.7678\n",
      "Epoch 20: val_accuracy improved from 0.77733 to 0.79082, saving model to sign_language_model.keras\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 0.7709 - accuracy: 0.7686 - val_loss: 0.7427 - val_accuracy: 0.7908\n",
      "Epoch 21/50\n",
      "185/185 [==============================] - ETA: 0s - loss: 0.8087 - accuracy: 0.7520\n",
      "Epoch 21: val_accuracy improved from 0.79082 to 0.80027, saving model to sign_language_model.keras\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 0.8087 - accuracy: 0.7520 - val_loss: 0.6984 - val_accuracy: 0.8003\n",
      "Epoch 22/50\n",
      "184/185 [============================>.] - ETA: 0s - loss: 0.7298 - accuracy: 0.7680\n",
      "Epoch 22: val_accuracy improved from 0.80027 to 0.81377, saving model to sign_language_model.keras\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 0.7313 - accuracy: 0.7672 - val_loss: 0.6322 - val_accuracy: 0.8138\n",
      "Epoch 23/50\n",
      "183/185 [============================>.] - ETA: 0s - loss: 0.7247 - accuracy: 0.7818\n",
      "Epoch 23: val_accuracy did not improve from 0.81377\n",
      "185/185 [==============================] - 1s 5ms/step - loss: 0.7224 - accuracy: 0.7821 - val_loss: 0.6695 - val_accuracy: 0.8097\n",
      "Epoch 24/50\n",
      "181/185 [============================>.] - ETA: 0s - loss: 0.6838 - accuracy: 0.7932\n",
      "Epoch 24: val_accuracy did not improve from 0.81377\n",
      "185/185 [==============================] - 1s 5ms/step - loss: 0.6911 - accuracy: 0.7905 - val_loss: 0.6542 - val_accuracy: 0.8124\n",
      "Epoch 25/50\n",
      "184/185 [============================>.] - ETA: 0s - loss: 0.6828 - accuracy: 0.7979\n",
      "Epoch 25: val_accuracy did not improve from 0.81377\n",
      "185/185 [==============================] - 1s 5ms/step - loss: 0.6842 - accuracy: 0.7980 - val_loss: 0.7467 - val_accuracy: 0.7719\n",
      "Epoch 26/50\n",
      "182/185 [============================>.] - ETA: 0s - loss: 0.6540 - accuracy: 0.8080\n",
      "Epoch 26: val_accuracy did not improve from 0.81377\n",
      "185/185 [==============================] - 1s 5ms/step - loss: 0.6607 - accuracy: 0.8061 - val_loss: 0.7622 - val_accuracy: 0.7611\n",
      "Epoch 27/50\n",
      "178/185 [===========================>..] - ETA: 0s - loss: 0.6415 - accuracy: 0.8083\n",
      "Epoch 27: val_accuracy did not improve from 0.81377\n",
      "185/185 [==============================] - 1s 5ms/step - loss: 0.6396 - accuracy: 0.8088 - val_loss: 0.6487 - val_accuracy: 0.8124\n",
      "Epoch 28/50\n",
      "178/185 [===========================>..] - ETA: 0s - loss: 0.5847 - accuracy: 0.8178\n",
      "Epoch 28: val_accuracy improved from 0.81377 to 0.84885, saving model to sign_language_model.keras\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 0.5824 - accuracy: 0.8189 - val_loss: 0.5702 - val_accuracy: 0.8489\n",
      "Epoch 29/50\n",
      "182/185 [============================>.] - ETA: 0s - loss: 0.5573 - accuracy: 0.8273\n",
      "Epoch 29: val_accuracy did not improve from 0.84885\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 0.5578 - accuracy: 0.8267 - val_loss: 0.5383 - val_accuracy: 0.8489\n",
      "Epoch 30/50\n",
      "184/185 [============================>.] - ETA: 0s - loss: 0.5896 - accuracy: 0.8268\n",
      "Epoch 30: val_accuracy did not improve from 0.84885\n",
      "185/185 [==============================] - 1s 5ms/step - loss: 0.5887 - accuracy: 0.8274 - val_loss: 0.5929 - val_accuracy: 0.8354\n",
      "Epoch 31/50\n",
      "177/185 [===========================>..] - ETA: 0s - loss: 0.5784 - accuracy: 0.8203\n",
      "Epoch 31: val_accuracy did not improve from 0.84885\n",
      "185/185 [==============================] - 1s 5ms/step - loss: 0.5797 - accuracy: 0.8186 - val_loss: 0.5578 - val_accuracy: 0.8489\n",
      "Epoch 32/50\n",
      "183/185 [============================>.] - ETA: 0s - loss: 0.5159 - accuracy: 0.8429\n",
      "Epoch 32: val_accuracy improved from 0.84885 to 0.85830, saving model to sign_language_model.keras\n",
      "185/185 [==============================] - 1s 5ms/step - loss: 0.5139 - accuracy: 0.8443 - val_loss: 0.5418 - val_accuracy: 0.8583\n",
      "Epoch 33/50\n",
      "183/185 [============================>.] - ETA: 0s - loss: 0.5484 - accuracy: 0.8340\n",
      "Epoch 33: val_accuracy did not improve from 0.85830\n",
      "185/185 [==============================] - 1s 5ms/step - loss: 0.5499 - accuracy: 0.8334 - val_loss: 0.7187 - val_accuracy: 0.7814\n",
      "Epoch 34/50\n",
      "185/185 [==============================] - ETA: 0s - loss: 0.5722 - accuracy: 0.8209\n",
      "Epoch 34: val_accuracy improved from 0.85830 to 0.86640, saving model to sign_language_model.keras\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 0.5722 - accuracy: 0.8209 - val_loss: 0.5032 - val_accuracy: 0.8664\n",
      "Epoch 35/50\n",
      "183/185 [============================>.] - ETA: 0s - loss: 0.4929 - accuracy: 0.8490\n",
      "Epoch 35: val_accuracy did not improve from 0.86640\n",
      "185/185 [==============================] - 1s 5ms/step - loss: 0.4928 - accuracy: 0.8486 - val_loss: 0.5210 - val_accuracy: 0.8543\n",
      "Epoch 36/50\n",
      "176/185 [===========================>..] - ETA: 0s - loss: 0.4723 - accuracy: 0.8533\n",
      "Epoch 36: val_accuracy did not improve from 0.86640\n",
      "185/185 [==============================] - 1s 5ms/step - loss: 0.4827 - accuracy: 0.8500 - val_loss: 0.5290 - val_accuracy: 0.8570\n",
      "Epoch 37/50\n",
      "179/185 [============================>.] - ETA: 0s - loss: 0.4703 - accuracy: 0.8596\n",
      "Epoch 37: val_accuracy did not improve from 0.86640\n",
      "185/185 [==============================] - 1s 5ms/step - loss: 0.4698 - accuracy: 0.8588 - val_loss: 0.4860 - val_accuracy: 0.8610\n",
      "Epoch 38/50\n",
      "181/185 [============================>.] - ETA: 0s - loss: 0.4302 - accuracy: 0.8785\n",
      "Epoch 38: val_accuracy did not improve from 0.86640\n",
      "185/185 [==============================] - 1s 5ms/step - loss: 0.4299 - accuracy: 0.8784 - val_loss: 0.4716 - val_accuracy: 0.8650\n",
      "Epoch 39/50\n",
      "172/185 [==========================>...] - ETA: 0s - loss: 0.4138 - accuracy: 0.8750\n",
      "Epoch 39: val_accuracy did not improve from 0.86640\n",
      "185/185 [==============================] - 1s 5ms/step - loss: 0.4206 - accuracy: 0.8740 - val_loss: 0.5217 - val_accuracy: 0.8570\n",
      "Epoch 40/50\n",
      "175/185 [===========================>..] - ETA: 0s - loss: 0.4979 - accuracy: 0.8514\n",
      "Epoch 40: val_accuracy did not improve from 0.86640\n",
      "185/185 [==============================] - 1s 5ms/step - loss: 0.4943 - accuracy: 0.8520 - val_loss: 0.5070 - val_accuracy: 0.8650\n",
      "Epoch 41/50\n",
      "180/185 [============================>.] - ETA: 0s - loss: 0.4559 - accuracy: 0.8538\n",
      "Epoch 41: val_accuracy did not improve from 0.86640\n",
      "185/185 [==============================] - 1s 5ms/step - loss: 0.4540 - accuracy: 0.8534 - val_loss: 0.4971 - val_accuracy: 0.8502\n",
      "Epoch 42/50\n",
      "175/185 [===========================>..] - ETA: 0s - loss: 0.4002 - accuracy: 0.8775\n",
      "Epoch 42: val_accuracy did not improve from 0.86640\n",
      "185/185 [==============================] - 1s 5ms/step - loss: 0.4154 - accuracy: 0.8730 - val_loss: 0.6171 - val_accuracy: 0.8124\n",
      "Epoch 43/50\n",
      "173/185 [===========================>..] - ETA: 0s - loss: 0.3866 - accuracy: 0.8887\n",
      "Epoch 43: val_accuracy improved from 0.86640 to 0.87179, saving model to sign_language_model.keras\n",
      "185/185 [==============================] - 1s 5ms/step - loss: 0.3873 - accuracy: 0.8872 - val_loss: 0.4454 - val_accuracy: 0.8718\n",
      "Epoch 44/50\n",
      "174/185 [===========================>..] - ETA: 0s - loss: 0.3744 - accuracy: 0.8886\n",
      "Epoch 44: val_accuracy did not improve from 0.87179\n",
      "185/185 [==============================] - 1s 5ms/step - loss: 0.3833 - accuracy: 0.8855 - val_loss: 0.5648 - val_accuracy: 0.8327\n",
      "Epoch 45/50\n",
      "179/185 [============================>.] - ETA: 0s - loss: 0.3909 - accuracy: 0.8785\n",
      "Epoch 45: val_accuracy did not improve from 0.87179\n",
      "185/185 [==============================] - 1s 5ms/step - loss: 0.3884 - accuracy: 0.8801 - val_loss: 0.4963 - val_accuracy: 0.8664\n",
      "Epoch 46/50\n",
      "178/185 [===========================>..] - ETA: 0s - loss: 0.3690 - accuracy: 0.8919\n",
      "Epoch 46: val_accuracy improved from 0.87179 to 0.88934, saving model to sign_language_model.keras\n",
      "185/185 [==============================] - 1s 5ms/step - loss: 0.3674 - accuracy: 0.8909 - val_loss: 0.4393 - val_accuracy: 0.8893\n",
      "Epoch 47/50\n",
      "183/185 [============================>.] - ETA: 0s - loss: 0.3488 - accuracy: 0.8904\n",
      "Epoch 47: val_accuracy did not improve from 0.88934\n",
      "185/185 [==============================] - 1s 5ms/step - loss: 0.3492 - accuracy: 0.8905 - val_loss: 0.4627 - val_accuracy: 0.8799\n",
      "Epoch 48/50\n",
      "180/185 [============================>.] - ETA: 0s - loss: 0.3801 - accuracy: 0.8819\n",
      "Epoch 48: val_accuracy did not improve from 0.88934\n",
      "185/185 [==============================] - 1s 5ms/step - loss: 0.3805 - accuracy: 0.8811 - val_loss: 0.4788 - val_accuracy: 0.8718\n",
      "Epoch 49/50\n",
      "178/185 [===========================>..] - ETA: 0s - loss: 0.4056 - accuracy: 0.8746\n",
      "Epoch 49: val_accuracy did not improve from 0.88934\n",
      "185/185 [==============================] - 1s 5ms/step - loss: 0.3984 - accuracy: 0.8770 - val_loss: 0.4592 - val_accuracy: 0.8812\n",
      "Epoch 50/50\n",
      "185/185 [==============================] - ETA: 0s - loss: 0.3468 - accuracy: 0.8949\n",
      "Epoch 50: val_accuracy did not improve from 0.88934\n",
      "185/185 [==============================] - 1s 5ms/step - loss: 0.3468 - accuracy: 0.8949 - val_loss: 0.5445 - val_accuracy: 0.8596\n",
      "\n",
      "âœ… Validation Loss: 0.5445\n",
      "âœ… Validation Accuracy: 0.8596\n",
      "\n",
      "ðŸ”¹ Continuing training with extra epochs...\n",
      "Epoch 1/15\n",
      "182/185 [============================>.] - ETA: 0s - loss: 0.3243 - accuracy: 0.9028\n",
      "Epoch 1: val_accuracy did not improve from 0.88934\n",
      "185/185 [==============================] - 3s 7ms/step - loss: 0.3264 - accuracy: 0.9020 - val_loss: 0.4947 - val_accuracy: 0.8623\n",
      "Epoch 2/15\n",
      "174/185 [===========================>..] - ETA: 0s - loss: 0.4183 - accuracy: 0.8646\n",
      "Epoch 2: val_accuracy did not improve from 0.88934\n",
      "185/185 [==============================] - 1s 5ms/step - loss: 0.4177 - accuracy: 0.8649 - val_loss: 0.4958 - val_accuracy: 0.8570\n",
      "Epoch 3/15\n",
      "181/185 [============================>.] - ETA: 0s - loss: 0.3641 - accuracy: 0.8895\n",
      "Epoch 3: val_accuracy did not improve from 0.88934\n",
      "185/185 [==============================] - 1s 5ms/step - loss: 0.3636 - accuracy: 0.8892 - val_loss: 0.4240 - val_accuracy: 0.8893\n",
      "Epoch 4/15\n",
      "174/185 [===========================>..] - ETA: 0s - loss: 0.3528 - accuracy: 0.8915\n",
      "Epoch 4: val_accuracy did not improve from 0.88934\n",
      "185/185 [==============================] - 1s 5ms/step - loss: 0.3501 - accuracy: 0.8919 - val_loss: 0.4347 - val_accuracy: 0.8866\n",
      "Epoch 5/15\n",
      "175/185 [===========================>..] - ETA: 0s - loss: 0.3307 - accuracy: 0.9000\n",
      "Epoch 5: val_accuracy did not improve from 0.88934\n",
      "185/185 [==============================] - 1s 6ms/step - loss: 0.3254 - accuracy: 0.9020 - val_loss: 0.4701 - val_accuracy: 0.8799\n",
      "Epoch 6/15\n",
      "175/185 [===========================>..] - ETA: 0s - loss: 0.3325 - accuracy: 0.9011\n",
      "Epoch 6: val_accuracy did not improve from 0.88934\n",
      "185/185 [==============================] - 1s 5ms/step - loss: 0.3283 - accuracy: 0.9027 - val_loss: 0.4489 - val_accuracy: 0.8785\n",
      "Epoch 7/15\n",
      "174/185 [===========================>..] - ETA: 0s - loss: 0.3230 - accuracy: 0.9041\n",
      "Epoch 7: val_accuracy did not improve from 0.88934\n",
      "185/185 [==============================] - 1s 5ms/step - loss: 0.3371 - accuracy: 0.8993 - val_loss: 0.4875 - val_accuracy: 0.8650\n",
      "Epoch 8/15\n",
      "177/185 [===========================>..] - ETA: 0s - loss: 0.3870 - accuracy: 0.8757Restoring model weights from the end of the best epoch: 3.\n",
      "\n",
      "Epoch 8: val_accuracy did not improve from 0.88934\n",
      "185/185 [==============================] - 1s 5ms/step - loss: 0.3849 - accuracy: 0.8764 - val_loss: 0.4554 - val_accuracy: 0.8758\n",
      "Epoch 8: early stopping\n",
      "\n",
      "âœ… Final Validation Loss: 0.4240\n",
      "âœ… Final Validation Accuracy: 0.8893\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T08:39:32.718130Z",
     "start_time": "2026-01-10T08:39:02.501693Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# -------------------------\n",
    "# Settings\n",
    "# -------------------------\n",
    "MODEL_PATH = \"sign_language_model.keras\"\n",
    "SEQUENCE_LENGTH = 30\n",
    "N_FEATURES = 126\n",
    "CLASSES = [\"Baby\",\n",
    "\"Bad\",\n",
    "\"Brother\",\n",
    "\"Dad\",\n",
    "\"Eat\",\n",
    "\"Fine\",\n",
    "\"Friend\",\n",
    "\"Go\",\n",
    "\"Good\",\n",
    "\"Great\",\n",
    "\"He\",\n",
    "\"Help\",\n",
    "\"I\",\n",
    "\"Love\",\n",
    "\"My\",\n",
    "\"No\",\n",
    "\"Nothing\",\n",
    "\"Say\",\n",
    "\"See you later\",\n",
    "\"Sister\",\n",
    "\"Stop\",\n",
    "\"Teacher\",\n",
    "\"We\",\n",
    "\"What_s up\",\n",
    "\"Yes\",\n",
    "\"You\",\n",
    "\"again\",\n",
    "\"bathroom\",\n",
    "\"book\",\n",
    "\"busy\",\n",
    "\"do not want\",\n",
    "\"father\",\n",
    "\"finish\",\n",
    "\"forget\",\n",
    "\"happy\",\n",
    "\"hello\",\n",
    "\"how\",\n",
    "\"is\",\n",
    "\"learn\",\n",
    "\"like\",\n",
    "\"marry\",\n",
    "\"meet\",\n",
    "\"milk\",\n",
    "\"more\",\n",
    "\"mother\",\n",
    "\"name\",\n",
    "\"need\",\n",
    "\"nice\",\n",
    "\"please\",\n",
    "\"question\",\n",
    "\"right\",\n",
    "\"sad\",\n",
    "\"same\",\n",
    "\"see you letter\",\n",
    "\"sleep\",\n",
    "\"thank you\",\n",
    "\"want\",\n",
    "\"what\",\n",
    "\"when\",\n",
    "\"where\",\n",
    "\"which\",\n",
    "\"who\",\n",
    "\"why\",\n",
    "\"wrong\",\n",
    "\"your\"\n",
    "]  # add all your class names in correct order\n",
    "\n",
    "# -------------------------\n",
    "# Load model\n",
    "# -------------------------\n",
    "model = load_model(MODEL_PATH)\n",
    "\n",
    "# -------------------------\n",
    "# Label encoder\n",
    "# -------------------------\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(CLASSES)\n",
    "\n",
    "# -------------------------\n",
    "# Initialize MediaPipe\n",
    "# -------------------------\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "hands = mp_hands.Hands(\n",
    "    min_detection_confidence=0.7,\n",
    "    min_tracking_confidence=0.7\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Capture from webcam\n",
    "# -------------------------\n",
    "cap = cv2.VideoCapture(0)\n",
    "FRAME_WIDTH = 1280\n",
    "FRAME_HEIGHT = 720\n",
    "FPS = 30\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, FRAME_WIDTH)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, FRAME_HEIGHT)\n",
    "cap.set(cv2.CAP_PROP_FPS, FPS)\n",
    "\n",
    "print(\"Starting real-time testing...\")\n",
    "print(f\"Collecting {SEQUENCE_LENGTH} frames per prediction...\")\n",
    "\n",
    "sequence = []\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        continue\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    result = hands.process(rgb_frame)\n",
    "\n",
    "    # Initialize keypoints\n",
    "    left_hand_kp = [(0, 0, 0)] * 21\n",
    "    right_hand_kp = [(0, 0, 0)] * 21\n",
    "\n",
    "    if result.multi_hand_landmarks and result.multi_handedness:\n",
    "        for hand_landmarks, handedness in zip(result.multi_hand_landmarks, result.multi_handedness):\n",
    "            hand_label = handedness.classification[0].label\n",
    "            kp = [(lm.x, lm.y, lm.z) for lm in hand_landmarks.landmark]\n",
    "\n",
    "            if hand_label == \"Left\":\n",
    "                left_hand_kp = kp\n",
    "            else:\n",
    "                right_hand_kp = kp\n",
    "\n",
    "            mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "    # Flatten keypoints and append to sequence\n",
    "    row = [coord for kp in left_hand_kp + right_hand_kp for coord in kp]\n",
    "    sequence.append(row)\n",
    "\n",
    "    # Keep only the last SEQUENCE_LENGTH frames\n",
    "    if len(sequence) > SEQUENCE_LENGTH:\n",
    "        sequence = sequence[-SEQUENCE_LENGTH:]\n",
    "\n",
    "    # Predict if we have enough frames\n",
    "    if len(sequence) == SEQUENCE_LENGTH:\n",
    "        X_input = np.array(sequence, dtype=np.float32)\n",
    "        X_input = np.expand_dims(X_input, axis=0)  # shape (1, SEQUENCE_LENGTH, N_FEATURES)\n",
    "        pred = model.predict(X_input, verbose=0)\n",
    "        pred_class_index = np.argmax(pred)\n",
    "        confidence = np.max(pred)\n",
    "        pred_class_name = label_encoder.inverse_transform([pred_class_index])[0]\n",
    "\n",
    "        # Display prediction\n",
    "        cv2.putText(frame, f\"Prediction: {pred_class_name} ({confidence:.2f})\",\n",
    "                    (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "    # Show webcam frame\n",
    "    cv2.imshow(\"Real-Time Sign Language Test\", frame)\n",
    "\n",
    "    # Quit with 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "hands.close()\n"
   ],
   "id": "ee665fe72f087574",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\kongm\\PycharmProjects\\SignLanguage\\.venv3\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\kongm\\PycharmProjects\\SignLanguage\\.venv3\\lib\\site-packages\\keras\\src\\backend.py:6642: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\kongm\\PycharmProjects\\SignLanguage\\.venv3\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Starting real-time testing...\n",
      "Collecting 30 frames per prediction...\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5e9cb954456b5ddc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
